{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c619b80",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from rljax.algorithm import DQN\n",
    "from rljax.trainer import Trainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from classes import Env, Preprocess\n",
    "\n",
    "PATH = Path().cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55337539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_q_values(env, algo, file_name):\n",
    "    q_values = list()\n",
    "    for v in env.mapping.values():\n",
    "        q_values.append(algo.net.apply(algo.params, np.array([v, 0])))\n",
    "        \n",
    "    labels = {0: 'Long/Short', 1: 'Short/Long', 2: 'Flat'}\n",
    "    states = np.array(list(env.mapping.keys()))\n",
    "\n",
    "    df = pd.DataFrame(q_values, columns=['Long/Short', 'Short/Long', 'Flat'])\n",
    "\n",
    "    df.to_csv(PATH.joinpath('asset_data', file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6732b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = Preprocess(PATH.joinpath('asset_data', 'TBT_TBF_9_27_data.csv'), res_bin = 7)\n",
    "data = raw.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7658bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = Preprocess(PATH.joinpath('asset_data', 'TBT_TBF_9_28_data.csv'), res_bin = 7)\n",
    "test_data = test_raw.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696e3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rewards(current, last, action, p, c):\n",
    "    return sum(current) - sum(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7fd7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num steps: 2500     Return: 0.0   (0.2  )   Time: 0:01:01\n",
      "Num steps: 5000     Return: 0.0   (0.3  )   Time: 0:01:43\n"
     ]
    }
   ],
   "source": [
    "# 23,400 seconds between 9:30am and 4pm broken in 10 second increments\n",
    "\n",
    "NUM_AGENT_STEPS = 5_000\n",
    "SEED = 0\n",
    "DAYS = 1\n",
    "DAY = 2340//2\n",
    "\n",
    "env = Env(data, no_trade_period=5, fixed_buy_cost=0, fixed_sell_cost=0, steps=DAY*DAYS, reward_func=return_rewards)\n",
    "env_test = Env(test_data, no_trade_period=5, fixed_buy_cost=0, fixed_sell_cost=0, steps=DAY*DAYS, reward_func=return_rewards)\n",
    "\n",
    "algo = DQN(\n",
    "    num_agent_steps=NUM_AGENT_STEPS,\n",
    "    state_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    seed=SEED,\n",
    "    batch_size=256,\n",
    "    start_steps=1000,\n",
    "    update_interval=1,\n",
    "    update_interval_target=400,\n",
    "    eps_decay_steps=0,\n",
    "    loss_type=\"l2\",\n",
    "    lr=5e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    env=env,\n",
    "    env_test=env_test,\n",
    "    algo=algo,\n",
    "    log_dir=\"\",\n",
    "    num_agent_steps=NUM_AGENT_STEPS,\n",
    "    eval_interval=25_00,\n",
    "    seed=SEED,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test.plot('position_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733cd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test.summarize_decisions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b88b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values = list()\n",
    "for v in env.mapping.values():\n",
    "    q_values.append(algo.net.apply(algo.params, np.array([v, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e4cb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "labels = {0: 'Long/Short', 1: 'Short/Long', 2: 'Flat'}\n",
    "states = np.array(list(env.mapping.keys()))\n",
    "\n",
    "for idx, col in enumerate(np.array(q_values).T):\n",
    "    sort = np.argsort(-np.array(q_values).T[0])\n",
    "    plt.plot(states[sort], col[sort], label=labels[idx])\n",
    "   \n",
    "plt.title('Q-Values with No Costs')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.xlabel('Residual Imbalance States')\n",
    "\n",
    "mini = -1\n",
    "maxi = 5.5\n",
    "\n",
    "plt.yticks(ticks=np.arange(mini, maxi, 0.33)[11:], labels=np.round(np.arange(-1, 1, 0.1)[11:], 2))\n",
    "plt.savefig('figures/q_values_no_costs_sorted_long_short.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f915bde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q_values_TBT_TBF_9_27'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'TBT_TBF_9_27_data.csv'\n",
    "f'q_values_{s[:-9]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd0b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_q_values(env, algo, 'TESTING_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38bbba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num steps: 25000    Return: -0.0  (0.2  )   Time: 0:02:17\n",
      "Num steps: 25000    Return: 0.0   (0.3  )   Time: 0:02:15\n",
      "Num steps: 25000    Return: -0.0  (0.3  )   Time: 0:02:23\n",
      "Num steps: 25000    Return: -0.0  (0.2  )   Time: 0:02:22\n",
      "Num steps: 25000    Return: -0.0  (0.2  )   Time: 0:02:22\n"
     ]
    }
   ],
   "source": [
    "for file in {'TBT_TBF_9_27_data.csv', 'TBT_TBF_9_28_data.csv', 'TBT_TBF_9_29_data.csv', 'TBT_TBF_9_30_data.csv', 'TBT_TBF_10_1_data.csv'}:\n",
    "    raw = Preprocess(PATH.joinpath('asset_data', file), res_bin = 7)\n",
    "    data = raw.process()\n",
    "\n",
    "    # 23,400 seconds between 9:30am and 4pm broken in 10 second increments\n",
    "\n",
    "    NUM_AGENT_STEPS = 25_000\n",
    "    SEED = 0\n",
    "    DAYS = 1\n",
    "    DAY = 2340//2\n",
    "\n",
    "    env = Env(data, no_trade_period=5, fixed_buy_cost=0, fixed_sell_cost=0, steps=DAY*DAYS, reward_func=return_rewards)\n",
    "    env_test = env.copy_env()\n",
    "\n",
    "    algo = DQN(\n",
    "        num_agent_steps=NUM_AGENT_STEPS,\n",
    "        state_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        seed=SEED,\n",
    "        batch_size=256,\n",
    "        start_steps=1000,\n",
    "        update_interval=1,\n",
    "        update_interval_target=400,\n",
    "        eps_decay_steps=0,\n",
    "        loss_type=\"l2\",\n",
    "        lr=5e-5,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        env=env,\n",
    "        env_test=env_test,\n",
    "        algo=algo,\n",
    "        log_dir=\"\",\n",
    "        num_agent_steps=NUM_AGENT_STEPS,\n",
    "        eval_interval=25_000,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    save_q_values(env, algo, f'q_values_{file[:-9]}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
